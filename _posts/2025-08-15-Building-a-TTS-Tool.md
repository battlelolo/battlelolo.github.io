---
layout: default
title: "Building a TTS Tool for My Friend in One Hour"
date: 2025-08-15
categories: [tech]
tags: [tts, microsoft, ai, text to speech, azure]
---

# Building a TTS Tool for My Friend in One Hour

## The Ask

My friend asked if there was a service that could read academic papers aloud - not like NotebookLM which creates podcast-style summaries, but something that would actually read the original text. She wanted to listen to papers like audiobooks when her eyes got tired.

I didn't know of such a service, but since I'm familiar with Microsoft Azure Language Services, I offered to help: "Send me the paper and I'll make mp3 for you."

## The Reality Check

I thought this would be simple:
1. Extract text from PDF using Claude/ChatGPT/Grok  
2. Run it through Azure TTS (Text to Speech)
3. Done!

Wrong. Academic PDFs are messy. Extract text and you get dozens of co-author names, chart numbers, table data, footnotes - everything my friend didn't want to hear.

I tried asking different AIs to extract only title, abstract, and main content:
- Claude Sonnet: Failed
- Grok: Failed with errors  
- Claude Opus: Success

Turns out extracting clean content from academic PDFs is harder than expected.

## From Manual to Automated

I generated the MP3 using Azure TTS and made a tutorial video. But a week later, my friend was still hunting for paid PDF-to-speech services.

That's when I realized: I might not know the perfect PDF-to-text AI, but I can definitely build a basic TTS web app. 

So I coded one with Claude Sonnet, built it in Next.js, deployed on Vercel, and shared it.

This is why I love being able to code!!!

<img src="{{ site.baseurl }}/assets/images/2025/08/20250815.png" alt="tts" class="img-center">

FYI - Sharing code I used for this service:
jsx'use client';

import { useState } from 'react';

interface StatusState {
  message: string;
  type: 'error' | 'success' | 'loading' | '';
}

export default function Home() {
  const [apiKey, setApiKey] = useState<string>('api-key');
  const [region, setRegion] = useState<string>('eastus');
  const [voice, setVoice] = useState<string>('en-GB-RyanNeural');
  const [rate, setRate] = useState<string>('medium');
  const [text, setText] = useState<string>('Hello, this is Azure Speech text-to-speech demo. How are you today?');
  const [status, setStatus] = useState<StatusState>({ message: '', type: '' });
  const [isPlaying, setIsPlaying] = useState<boolean>(false);
  const [currentAudio, setCurrentAudio] = useState<HTMLAudioElement | null>(null);
  const [lastAudioBlob, setLastAudioBlob] = useState<Blob | null>(null);

  const showStatus = (message: string, type: StatusState['type']) => {
    setStatus({ message, type });
  };

  const testConnection = async () => {
    if (!apiKey || !region) {
      showStatus('API Keyì™€ Regionì„ ì…ë ¥í•´ì£¼ì„¸ìš”.', 'error');
      return;
    }
  };

  const speakLongText = async () => {
    const chunks = splitTextIntoChunks(text);
    
    if (chunks.length === 0) {
      showStatus('í…ìŠ¤íŠ¸ ë¶„í•  ì‹¤íŒ¨', 'error');
      return;
    }
    
    console.log(`í…ìŠ¤íŠ¸ë¥¼ ${chunks.length}ê°œ ì²­í¬ë¡œ ë¶„í• :`, chunks.map((c, i) => `${i + 1}: ${c.substring(0, 50)}...`));
    showStatus(`ê¸´ í…ìŠ¤íŠ¸ë¥¼ ${chunks.length}ê°œ ë¶€ë¶„ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ì²˜ë¦¬ ì¤‘...`, 'loading');

    const audioChunks: Blob[] = [];
    let accessToken = '';

    try {
      // ì•¡ì„¸ìŠ¤ í† í° ë°œê¸‰
      console.log('í† í° ë°œê¸‰ ì‹œë„...');
      const tokenResponse = await fetch(`https://${region}.api.cognitive.microsoft.com/sts/v1.0/issueToken`, {
        method: 'POST',
        headers: {
          'Ocp-Apim-Subscription-Key': apiKey
        }
      });

      if (!tokenResponse.ok) {
        const errorText = await tokenResponse.text();
        console.error('í† í° ë°œê¸‰ ì‹¤íŒ¨:', tokenResponse.status, errorText);
        throw new Error(`í† í° ë°œê¸‰ ì‹¤íŒ¨: ${tokenResponse.status}`);
      }

      accessToken = await tokenResponse.text();
      console.log('í† í° ë°œê¸‰ ì„±ê³µ');

      // ê° ì²­í¬ë¥¼ ìˆœì„œëŒ€ë¡œ ì²˜ë¦¬
      for (let i = 0; i < chunks.length; i++) {
        console.log(`ì²­í¬ ${i + 1}/${chunks.length} ì²˜ë¦¬ ì¤‘... (ê¸¸ì´: ${chunks[i].length}ì)`);
        showStatus(`ìŒì„± ìƒì„± ì¤‘... (${i + 1}/${chunks.length})`, 'loading');

        try {
          // SSMLì—ì„œ íŠ¹ìˆ˜ë¬¸ì ì´ìŠ¤ì¼€ì´í”„
          const escapedText = chunks[i]
            .replace(/&/g, '&amp;')
            .replace(/</g, '&lt;')
            .replace(/>/g, '&gt;')
            .replace(/"/g, '&quot;')
            .replace(/'/g, '&apos;');

          const ssml = `<speak version='1.0' xml:lang='en-US'><voice xml:lang='en-US' name='${voice}'><prosody rate='${rate}'>${escapedText}</prosody></voice></speak>`;

          const ttsResponse = await fetch(`https://${region}.tts.speech.microsoft.com/cognitiveservices/v1`, {
            method: 'POST',
            headers: {
              'Authorization': 'Bearer ' + accessToken,
              'Content-Type': 'application/ssml+xml',
              'X-Microsoft-OutputFormat': 'audio-16khz-128kbitrate-mono-mp3',
              'User-Agent': 'NextJS-TTS-App'
            },
            body: ssml
          });

          if (!ttsResponse.ok) {
            const errorText = await ttsResponse.text();
            console.error(`ì²­í¬ ${i + 1} TTS ì‹¤íŒ¨:`, ttsResponse.status, errorText);
            
            // 401 ì˜¤ë¥˜ì‹œ í† í° ì¬ë°œê¸‰ ì‹œë„
            if (ttsResponse.status === 401) {
              console.log('í† í° ì¬ë°œê¸‰ ì‹œë„...');
              const newTokenResponse = await fetch(`https://${region}.api.cognitive.microsoft.com/sts/v1.0/issueToken`, {
                method: 'POST',
                headers: {
                  'Ocp-Apim-Subscription-Key': apiKey
                }
              });
              
              if (newTokenResponse.ok) {
                accessToken = await newTokenResponse.text();
                i--; // í˜„ì¬ ì²­í¬ ì¬ì‹œë„
                continue;
              }
            }
            
            throw new Error(`TTS ìš”ì²­ ì‹¤íŒ¨ (ì²­í¬ ${i + 1}): ${ttsResponse.status}`);
          }

          const audioBlob = await ttsResponse.blob();
          
          if (audioBlob.size === 0) {
            console.warn(`ì²­í¬ ${i + 1}ì—ì„œ ë¹ˆ ì˜¤ë””ì˜¤ ì‘ë‹µ`);
            continue;
          }
          
          console.log(`ì²­í¬ ${i + 1} ì™„ë£Œ, í¬ê¸°:`, audioBlob.size, 'bytes');
          audioChunks.push(audioBlob);

        } catch (chunkError) {
          console.error(`ì²­í¬ ${i + 1} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜:`, chunkError);
          showStatus(`ì²­í¬ ${i + 1} ì²˜ë¦¬ ì‹¤íŒ¨, ê³„ì† ì§„í–‰...`, 'loading');
          continue; // ë‹¤ìŒ ì²­í¬ë¡œ ê³„ì†
        }

        // API ì œí•œì„ í”¼í•˜ê¸° ìœ„í•œ ì§€ì—° (ì¦ê°€)
        if (i < chunks.length - 1) {
          await new Promise(resolve => setTimeout(resolve, 1500));
        }
      }

      if (audioChunks.length === 0) {
        throw new Error('ì²˜ë¦¬ëœ ì˜¤ë””ì˜¤ ì²­í¬ê°€ ì—†ìŠµë‹ˆë‹¤');
      }

      console.log(`${audioChunks.length}ê°œ ì²­í¬ ì™„ë£Œ, ê²°í•© ì¤‘...`);
      
      // ëª¨ë“  ì˜¤ë””ì˜¤ ì²­í¬ë¥¼ í•˜ë‚˜ë¡œ í•©ì¹˜ê¸°
      const combinedBlob = new Blob(audioChunks, { type: 'audio/mpeg' });
      console.log('ê²°í•©ëœ ì˜¤ë””ì˜¤ í¬ê¸°:', combinedBlob.size, 'bytes');
      setLastAudioBlob(combinedBlob);

      // ì¬ìƒ
      const audioUrl = URL.createObjectURL(combinedBlob);
      const audio = new Audio(audioUrl);
      setCurrentAudio(audio);
      setIsPlaying(true);
      
      audio.addEventListener('canplay', () => {
        console.log('ì˜¤ë””ì˜¤ ì¬ìƒ ì¤€ë¹„ ì™„ë£Œ');
      });

      audio.play().catch(playError => {
        console.error('ì˜¤ë””ì˜¤ ì¬ìƒ ì˜¤ë¥˜:', playError);
        showStatus('ì˜¤ë””ì˜¤ ì¬ìƒ ì‹¤íŒ¨', 'error');
        setIsPlaying(false);
        setCurrentAudio(null);
      });

      showStatus(`ì „ì²´ ìŒì„± ì¬ìƒ ì¤‘... (${audioChunks.length}/${chunks.length}ê°œ ë¶€ë¶„ ê²°í•©)`, 'success');

      audio.onended = () => {
        showStatus('ê¸´ í…ìŠ¤íŠ¸ ìŒì„± ì¬ìƒ ì™„ë£Œ!', 'success');
        setIsPlaying(false);
        setCurrentAudio(null);
        URL.revokeObjectURL(audioUrl);
      };

      audio.onerror = (e) => {
        console.error('ì˜¤ë””ì˜¤ ì¬ìƒ ì˜¤ë¥˜:', e);
        showStatus('ì˜¤ë””ì˜¤ ì¬ìƒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ', 'error');
        setIsPlaying(false);
        setCurrentAudio(null);
        URL.revokeObjectURL(audioUrl);
      };

    } catch (error) {
      console.error('ê¸´ í…ìŠ¤íŠ¸ ì²˜ë¦¬ ì „ì²´ ì˜¤ë¥˜:', error);
      showStatus('ê¸´ í…ìŠ¤íŠ¸ ì²˜ë¦¬ ì˜¤ë¥˜: ' + (error as Error).message, 'error');
    }

    try {
      const response = await fetch(`https://${region}.api.cognitive.microsoft.com/sts/v1.0/issueToken`, {
        method: 'POST',
        headers: {
          'Ocp-Apim-Subscription-Key': apiKey,
          'Content-Type': 'application/x-www-form-urlencoded'
        }
      });

      if (response.ok) {
        showStatus('API ì—°ê²° ì„±ê³µ!', 'success');
      } else {
        showStatus('API ì—°ê²° ì‹¤íŒ¨: ' + response.status, 'error');
      }
    } catch (error) {
      showStatus('ì—°ê²° ì˜¤ë¥˜: ' + (error as Error).message, 'error');
    }
  };

  const splitTextIntoChunks = (text: string, maxLength: number = 2000): string[] => {
    // ë¨¼ì € ë¬¸ë‹¨ìœ¼ë¡œ ë‚˜ëˆ„ê¸°
    const paragraphs = text.split(/\n\s*\n/).filter(p => p.trim());
    const chunks: string[] = [];
    
    for (const paragraph of paragraphs) {
      if (paragraph.length <= maxLength) {
        chunks.push(paragraph.trim());
      } else {
        // ë¬¸ë‹¨ì´ ë„ˆë¬´ ê¸¸ë©´ ë¬¸ì¥ìœ¼ë¡œ ë‚˜ëˆ„ê¸°
        const sentences = paragraph.split(/(?<=[.!?])\s+/).filter(s => s.trim());
        let currentChunk = '';
        
        for (const sentence of sentences) {
          const testChunk = currentChunk + (currentChunk ? ' ' : '') + sentence;
          
          if (testChunk.length <= maxLength) {
            currentChunk = testChunk;
          } else {
            if (currentChunk) {
              chunks.push(currentChunk.trim());
              currentChunk = sentence;
            } else {
              // ë¬¸ì¥ë„ ë„ˆë¬´ ê¸¸ë©´ ê°•ì œë¡œ ìë¥´ê¸°
              const words = sentence.split(' ');
              let wordChunk = '';
              
              for (const word of words) {
                if ((wordChunk + ' ' + word).length <= maxLength) {
                  wordChunk += (wordChunk ? ' ' : '') + word;
                } else {
                  if (wordChunk) chunks.push(wordChunk.trim());
                  wordChunk = word;
                }
              }
              if (wordChunk) chunks.push(wordChunk.trim());
            }
          }
        }
        
        if (currentChunk) {
          chunks.push(currentChunk.trim());
        }
      }
    }
    
    return chunks.filter(chunk => chunk.length > 0);
  };

  const speakText = async () => {
    if (!apiKey || !region) {
      showStatus('API Keyì™€ Regionì„ ì…ë ¥í•´ì£¼ì„¸ìš”.', 'error');
      return;
    }

    if (!text.trim()) {
      showStatus('í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.', 'error');
      return;
    }

    // ê¸´ í…ìŠ¤íŠ¸ì¸ì§€ í™•ì¸ (ì„ê³„ê°’ì„ ë‚®ì¶¤)
    if (text.length > 2000) {
      await speakLongText();
      return;
    }

    showStatus('ìŒì„± ìƒì„± ì¤‘...', 'loading');

    try {
      // 1. ì•¡ì„¸ìŠ¤ í† í° ë°œê¸‰
      const tokenResponse = await fetch(`https://${region}.api.cognitive.microsoft.com/sts/v1.0/issueToken`, {
        method: 'POST',
        headers: {
          'Ocp-Apim-Subscription-Key': apiKey
        }
      });

      if (!tokenResponse.ok) {
        throw new Error('í† í° ë°œê¸‰ ì‹¤íŒ¨');
      }

      const accessToken = await tokenResponse.text();

      // 2. SSML ìƒì„±
      const ssml = `
        <speak version='1.0' xml:lang='en-US'>
          <voice xml:lang='en-US' name='${voice}'>
            <prosody rate='${rate}'>
              ${text}
            </prosody>
          </voice>
        </speak>
      `;

      // 3. TTS API í˜¸ì¶œ
      const ttsResponse = await fetch(`https://${region}.tts.speech.microsoft.com/cognitiveservices/v1`, {
        method: 'POST',
        headers: {
          'Authorization': 'Bearer ' + accessToken,
          'Content-Type': 'application/ssml+xml',
          'X-Microsoft-OutputFormat': 'audio-16khz-128kbitrate-mono-mp3'
        },
        body: ssml
      });

      if (!ttsResponse.ok) {
        throw new Error('TTS ìš”ì²­ ì‹¤íŒ¨: ' + ttsResponse.status);
      }

      // 4. ì˜¤ë””ì˜¤ ì¬ìƒ
      const audioBlob = await ttsResponse.blob();
      setLastAudioBlob(audioBlob);

      const audioUrl = URL.createObjectURL(audioBlob);
      const audio = new Audio(audioUrl);

      audio.play();
      showStatus('ìŒì„± ì¬ìƒ ì¤‘... (MP3 ë‹¤ìš´ë¡œë“œ ê°€ëŠ¥)', 'success');

      audio.onended = () => {
        showStatus('ìŒì„± ì¬ìƒ ì™„ë£Œ!', 'success');
        URL.revokeObjectURL(audioUrl);
      };

    } catch (error) {
      showStatus('ì˜¤ë¥˜: ' + (error as Error).message, 'error');
    }
  };

  const stopAudio = () => {
    if (currentAudio) {
      currentAudio.pause();
      currentAudio.currentTime = 0;
      setCurrentAudio(null);
      setIsPlaying(false);
      showStatus('ìŒì„± ì¬ìƒì´ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.', 'success');
    }
  };

  const generateMp3Only = async () => {
    if (!apiKey || !region) {
      showStatus('API Keyì™€ Regionì„ ì…ë ¥í•´ì£¼ì„¸ìš”.', 'error');
      return;
    }

    if (!text.trim()) {
      showStatus('í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.', 'error');
      return;
    }

    if (text.length > 2000) {
      await generateLongMp3();
      return;
    }

    showStatus('MP3 íŒŒì¼ ìƒì„± ì¤‘...', 'loading');

    try {
      const tokenResponse = await fetch(`https://${region}.api.cognitive.microsoft.com/sts/v1.0/issueToken`, {
        method: 'POST',
        headers: {
          'Ocp-Apim-Subscription-Key': apiKey
        }
      });

      if (!tokenResponse.ok) {
        throw new Error('í† í° ë°œê¸‰ ì‹¤íŒ¨');
      }

      const accessToken = await tokenResponse.text();
      const escapedText = text
        .replace(/&/g, '&amp;')
        .replace(/</g, '&lt;')
        .replace(/>/g, '&gt;')
        .replace(/"/g, '&quot;')
        .replace(/'/g, '&apos;');

      const ssml = `<speak version='1.0' xml:lang='en-US'><voice xml:lang='en-US' name='${voice}'><prosody rate='${rate}'>${escapedText}</prosody></voice></speak>`;

      const ttsResponse = await fetch(`https://${region}.tts.speech.microsoft.com/cognitiveservices/v1`, {
        method: 'POST',
        headers: {
          'Authorization': 'Bearer ' + accessToken,
          'Content-Type': 'application/ssml+xml',
          'X-Microsoft-OutputFormat': 'audio-16khz-128kbitrate-mono-mp3'
        },
        body: ssml
      });

      if (!ttsResponse.ok) {
        throw new Error('TTS ìš”ì²­ ì‹¤íŒ¨: ' + ttsResponse.status);
      }

      const audioBlob = await ttsResponse.blob();
      setLastAudioBlob(audioBlob);
      
      // ìë™ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œ
      downloadMp3(audioBlob);

    } catch (error) {
      showStatus('MP3 ìƒì„± ì˜¤ë¥˜: ' + (error as Error).message, 'error');
    }
  };

  const generateLongMp3 = async () => {
    const chunks = splitTextIntoChunks(text);
    
    if (chunks.length === 0) {
      showStatus('í…ìŠ¤íŠ¸ ë¶„í•  ì‹¤íŒ¨', 'error');
      return;
    }
    
    showStatus(`MP3 íŒŒì¼ ìƒì„± ì¤‘... (${chunks.length}ê°œ ë¶€ë¶„)`, 'loading');
    const audioChunks: Blob[] = [];
    let accessToken = '';

    try {
      const tokenResponse = await fetch(`https://${region}.api.cognitive.microsoft.com/sts/v1.0/issueToken`, {
        method: 'POST',
        headers: {
          'Ocp-Apim-Subscription-Key': apiKey
        }
      });

      if (!tokenResponse.ok) {
        throw new Error(`í† í° ë°œê¸‰ ì‹¤íŒ¨: ${tokenResponse.status}`);
      }

      accessToken = await tokenResponse.text();

      for (let i = 0; i < chunks.length; i++) {
        showStatus(`MP3 ìƒì„± ì¤‘... (${i + 1}/${chunks.length})`, 'loading');

        const escapedText = chunks[i]
          .replace(/&/g, '&amp;')
          .replace(/</g, '&lt;')
          .replace(/>/g, '&gt;')
          .replace(/"/g, '&quot;')
          .replace(/'/g, '&apos;');

        const ssml = `<speak version='1.0' xml:lang='en-US'><voice xml:lang='en-US' name='${voice}'><prosody rate='${rate}'>${escapedText}</prosody></voice></speak>`;

        const ttsResponse = await fetch(`https://${region}.tts.speech.microsoft.com/cognitiveservices/v1`, {
          method: 'POST',
          headers: {
            'Authorization': 'Bearer ' + accessToken,
            'Content-Type': 'application/ssml+xml',
            'X-Microsoft-OutputFormat': 'audio-16khz-128kbitrate-mono-mp3'
          },
          body: ssml
        });

        if (!ttsResponse.ok) {
          if (ttsResponse.status === 401) {
            const newTokenResponse = await fetch(`https://${region}.api.cognitive.microsoft.com/sts/v1.0/issueToken`, {
              method: 'POST',
              headers: {
                'Ocp-Apim-Subscription-Key': apiKey
              }
            });
            
            if (newTokenResponse.ok) {
              accessToken = await newTokenResponse.text();
              i--;
              continue;
            }
          }
          throw new Error(`TTS ìš”ì²­ ì‹¤íŒ¨ (ì²­í¬ ${i + 1}): ${ttsResponse.status}`);
        }

        const audioBlob = await ttsResponse.blob();
        if (audioBlob.size > 0) {
          audioChunks.push(audioBlob);
        }

        if (i < chunks.length - 1) {
          await new Promise(resolve => setTimeout(resolve, 1500));
        }
      }

      if (audioChunks.length === 0) {
        throw new Error('ì²˜ë¦¬ëœ ì˜¤ë””ì˜¤ ì²­í¬ê°€ ì—†ìŠµë‹ˆë‹¤');
      }

      const combinedBlob = new Blob(audioChunks, { type: 'audio/mpeg' });
      setLastAudioBlob(combinedBlob);
      
      // ìë™ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œ
      downloadMp3(combinedBlob);

    } catch (error) {
      showStatus('ê¸´ í…ìŠ¤íŠ¸ MP3 ìƒì„± ì˜¤ë¥˜: ' + (error as Error).message, 'error');
    }
  };
  const downloadMp3 = (blob?: Blob) => {
    const audioBlob = blob || lastAudioBlob;
    
    if (!audioBlob) {
      showStatus('ë¨¼ì € ìŒì„±ì„ ìƒì„±í•´ì£¼ì„¸ìš”.', 'error');
      return;
    }

    const url = URL.createObjectURL(audioBlob);
    const a = document.createElement('a');
    a.href = url;
    a.download = 'azure-speech-' + new Date().getTime() + '.mp3';
    document.body.appendChild(a);
    a.click();
    document.body.removeChild(a);
    URL.revokeObjectURL(url);

    showStatus('MP3 íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!', 'success');
  };

  const getStatusStyle = (): React.CSSProperties => {
    const baseStyle: React.CSSProperties = {
      marginTop: '20px',
      padding: '10px',
      border: '1px solid #ccc',
      display: status.message ? 'block' : 'none'
    };

    if (status.type === 'error') {
      return {
        ...baseStyle,
        backgroundColor: '#ffebee',
        color: '#c62828',
        borderColor: '#e57373'
      };
    } else if (status.type === 'success') {
      return {
        ...baseStyle,
        backgroundColor: '#e8f5e8',
        color: '#2e7d32',
        borderColor: '#81c784'
      };
    } else {
      return {
        ...baseStyle,
        backgroundColor: '#fff3e0',
        color: '#ef6c00',
        borderColor: '#ffb74d'
      };
    }
  };

  return (
    <div style={{ maxWidth: '800px', margin: '0 auto', padding: '20px' }}>
      <h1>Azure Speech Text-to-Speech</h1>

      <h3>API ì„¤ì •</h3>
      <input
        type="text"
        value={apiKey}
        onChange={(e) => setApiKey(e.target.value)}
        placeholder="Azure Speech API Key"
        style={{ width: '300px', marginRight: '10px' }}
      />
      <input
        type="text"
        value={region}
        onChange={(e) => setRegion(e.target.value)}
        placeholder="Region (ì˜ˆ: koreacentral)"
        style={{ width: '200px', marginRight: '10px' }}
      />
      <button onClick={testConnection}>ì—°ê²° í…ŒìŠ¤íŠ¸</button>

      <h3>ìŒì„± ì„¤ì •</h3>
      <select
        value={voice}
        onChange={(e) => setVoice(e.target.value)}
        style={{ width: '250px', marginRight: '10px' }}
      >
        <option value="en-US-AvaNeural">en-US-AvaNeural (ì—¬ì„±)</option>
        <option value="en-US-AndrewNeural">en-US-AndrewNeural (ë‚¨ì„±)</option>
        <option value="en-US-EmmaNeural">en-US-EmmaNeural (ì—¬ì„±)</option>
        <option value="en-US-BrianNeural">en-US-BrianNeural (ë‚¨ì„±)</option>
        <option value="en-GB-SoniaNeural">en-GB-SoniaNeural (ì˜êµ­ ì—¬ì„±)</option>
        <option value="en-GB-RyanNeural">en-GB-RyanNeural (ì˜êµ­ ë‚¨ì„±)</option>
      </select>

      ì†ë„: 
      <select
        value={rate}
        onChange={(e) => setRate(e.target.value)}
        style={{ marginLeft: '10px' }}
      >
        <option value="x-slow">ë§¤ìš° ëŠë¦¬ê²Œ</option>
        <option value="slow">ëŠë¦¬ê²Œ</option>
        <option value="medium">ë³´í†µ</option>
        <option value="fast">ë¹ ë¥´ê²Œ</option>
        <option value="x-fast">ë§¤ìš° ë¹ ë¥´ê²Œ</option>
      </select>

      <h3>í…ìŠ¤íŠ¸</h3>
      <textarea
        value={text}
        onChange={(e) => setText(e.target.value)}
        rows={8}
        cols={60}
        placeholder="ì—¬ê¸°ì— ì˜ì–´ í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”... (ê¸´ í…ìŠ¤íŠ¸ë„ ìë™ìœ¼ë¡œ ë¶„í•  ì²˜ë¦¬ë©ë‹ˆë‹¤)"
        style={{ width: '100%', maxWidth: '600px' }}
      />
      <div style={{ fontSize: '12px', color: '#666', marginTop: '5px' }}>
        í˜„ì¬ ê¸€ì ìˆ˜: {text.length} / ê¶Œì¥: 2,000ì ì´í•˜ (ê¸´ í…ìŠ¤íŠ¸ëŠ” ìë™ ë¶„í• ë©ë‹ˆë‹¤)
      </div>
      <br />

      <button 
        onClick={speakText} 
        disabled={isPlaying}
        style={{ 
          marginRight: '10px',
          opacity: isPlaying ? 0.6 : 1,
          cursor: isPlaying ? 'not-allowed' : 'pointer'
        }}
      >
        ğŸ”Š ë§í•˜ê¸°
      </button>
      
      {isPlaying && (
        <button 
          onClick={stopAudio}
          style={{ 
            marginRight: '10px',
            backgroundColor: '#dc3545',
            color: 'white',
            border: 'none',
            padding: '12px 20px',
            borderRadius: '8px',
            cursor: 'pointer'
          }}
        >
          â¹ï¸ ì •ì§€
        </button>
      )}
      
      <button 
        onClick={generateMp3Only}
        style={{ 
          marginRight: '10px',
          backgroundColor: '#28a745',
          color: 'white',
          border: 'none',
          padding: '12px 20px',
          borderRadius: '8px',
          cursor: 'pointer'
        }}
      >
        ğŸ’¾ MP3 ìƒì„±/ë‹¤ìš´ë¡œë“œ
      </button>
      
      {lastAudioBlob && (
        <button 
          onClick={() => downloadMp3()}
          style={{ 
            backgroundColor: '#17a2b8',
            color: 'white',
            border: 'none',
            padding: '12px 20px',
            borderRadius: '8px',
            cursor: 'pointer'
          }}
        >
          ğŸ“ ë§ˆì§€ë§‰ MP3 ë‹¤ì‹œ ë‹¤ìš´ë¡œë“œ
        </button>
      )}

      <div style={getStatusStyle()}>
        {status.message}
      </div>
    </div>
  );
}

---

## ğŸ“Œ Navigation
- [â† All Posts](/posts)
- [ğŸ  Home](/)
<!-- - [ğŸ“§ Contact](/contact) -->

{% if page.previous %}
**Previous:** [{{ page.previous.title }}]({{ page.previous.url }})
{% endif %}

{% if page.next %}
**Next:** [{{ page.next.title }}]({{ page.next.url }})
{% endif %}
